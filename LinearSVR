#!/usr/bin/env python3.7

import pandas as pd
import numpy as np
import os
import statsmodels.api as sm
import matplotlib.pyplot as plt
from statsmodels.tsa.stattools import adfuller
from sklearn.preprocessing import (PolynomialFeatures, Normalizer, StandardScaler)
from sklearn.neighbors import LocalOutlierFactor
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.pipeline import make_pipeline
from sklearn.svm import LinearSVR
from sklearn.utils.sparsefuncs import (mean_variance_axis, inplace_column_scale)
from scipy.sparse import csr_matrix



path = 'path'
rel_path = 'file.csv'
ctg_file = 'ctg.csv'
filename = 'output.xlsx'

df = pd.read_csv(os.path.join(path, rel_path))
ctg_ls = pd.read_excel(os.path.join(path, ctg_file))

df = df[df['ctg'].isin(ctg_ls['ctg'].unique())]

n = 20
col = [cols]
for s in sorted(df['ctg'].unique(), reverse=True):
    df_ctg_pos = df[(df['ctg']==s) & (df['col1']>=0)]
    df_ctg_all = df[df['ctg']==s]
    df_ctg_neg = df[(df['ctg']==s) & (df['col1']<=0)]
    
    param_dict = {}
    df_dict = {'pos': df_ctg_pos, 'all': df_ctg_all, 'neg': df_ctg_neg}
    for k in df_dict.keys():
        df_ctg = df_dict[k]
        if len(df_ctg) > n:
            X = df_ctg[col]
            X = np.ma.masked_invalid(X)
            X[:, 2] = np.sqrt(X[:, 2])
            X[:, 3] = np.sqrt(X[:, 3])
            ts = adfuller(df_ctg[['col6', 'col7']].groupby('col6').sum(), autolag='AIC')
            if ts[0] > ts[4]['5%']:
                X = PolynomialFeatures(degree=2, interaction_only=True, include_bias=False).fit_transform(X).astype(int)
            
            y = df_ctg['col1']
            
            clf = LocalOutlierFactor(n_neighbors=n, contamination=0.2)
            y_pred = clf.fit_predict(X)
            X = X[y_pred==1]
            y = y[y_pred==1]
            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.33, random_state=0)
            
            transformer = Normalizer()
            scaler = StandardScaler()
            svm_reg = make_pipeline(scaler, transformer, LinearSVR(C=1.0, epsilon=0.1, random_state=0, tol=1e-3)).fit(X_train, y_train)
            r_sq = svm_reg.score(X_train, y_train)
            mean_err = np.mean((svm_reg.predict(X_test) - y_test)**2)
            mean_y_test = y_test.mean()
            
            X_test_scale = csr_matrix(X_test)
            mean_ax, var_ax = mean_variance_axis(X_test_scale, axis=0)
            mean_ax, var_ax = np.round(mean_ax, 3), np.round(var_ax, 3)
            var_ax[var_ax==0.0] = 1.0
            
            l2 = np.linalg.norm(X_test, axis=0)
            l2[l2==0] = 1
            X_test_scale = csr_matrix((X_test_scale/l2.T) - mean_ax)
            
            inplace_column_scale(X_test_scale, 1 / np.sqrt(var_ax))
            w = svm_reg['linearsvr'].coef_
            b = svm_reg['linearsvr'].intercept_
            mean_err_form = np.mean(((np.dot(X_test_scale.toarray(), w.T) + b) - y_test)**2)
            
            param_dict[k] = np.array([r_sq, mean_y_test, mean_err, mean_err_form, X_test, X_test_scale, w, b, X_train, y_train, y_test, mean_ax, var_ax])





# h = 0.2
# x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1
# y_min, y_max = y.min() - 1, y.max() + 1
# xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))
# Z = svm_reg.predict(np.c_[xx.ravel(), xx.ravel(), xx.ravel(), yy.ravel()]).reshape(xx.shape)

# plt.contourf(xx, yy, Z, cmap=plt.cm.coolwarm, alpha=0.8)
# plt.scatter(X[:, 0], y, c=y, cmap=plt.cm.coolwarm)
# plt.show()
